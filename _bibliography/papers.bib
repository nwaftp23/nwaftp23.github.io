---
---

@string{aps = {American Physical Society,}}
@article{berry2025seeing,
  title={Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models},
  author={Berry, Lucas and Brando, Axel and Chang, Wei-Di and Higuera, Juan Camilo Gamboa and Meger, David},
  journal={arXiv preprint arXiv:2505.13273},
  year={2025},
  pdf={https://arxiv.org/pdf/2505.13273},
  selected={true},
  arxiv={2505.13273},
  abstract={Estimating uncertainty in text-to-image diffusion models is challenging because of their large parameter counts (often exceeding 100 million) and operation in complex, high-dimensional spaces with virtually infinite input possibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a novel framework for efficiently estimating epistemic uncertainty in diffusion models. EMoE leverages pre-trained networks without requiring additional training, enabling direct uncertainty estimation from a prompt. We leverage a latent space within the diffusion process that captures epistemic uncertainty better than existing methods. Experimental results on the COCO dataset demonstrate EMoE’s effectiveness, showing a strong correlation between uncertainty and image quality. Additionally, EMoE identifies under-sampled languages and regions with higher uncertainty, revealing hidden biases in the training set. This capability demonstrates the relevance of EMoE as a tool for addressing fairness and accountability in AI-generated content.},
}
@article{berry2023escaping,
  title={Efficient Epistemic Uncertainty Estimation in Regression Ensemble Models Using Pairwise-Distance Estimators},
  author={Berry, Lucas and Meger, David},
  journal={Thirty-Ninth Annual Conference on Neural Information Processing Systems},
  abbr={NeurIPS},
  year={2025},
  pdf={https://arxiv.org/pdf/2308.13498},
  code={https://github.com/nwaftp23/pairflow-uncertainty},
  selected={true},
  arxiv={2308.13498},
  abstract={This work introduces a novel approach, Pairwise Epistemic Estimators (PairEpEsts), for epistemic uncertainty estimation in ensemble models for regression tasks using pairwise-distance estimators (PaiDEs). By utilizing the pairwise distances between model components, PaiDEs establish bounds on entropy. We leverage this capability to enhance the performance of Bayesian Active Learning by Disagreement (BALD). Notably, unlike sample-based Monte Carlo estimators, PairEpEsts can estimate epistemic uncertainty up to 100 times faster and demonstrate superior performance in higher dimensions. To validate our approach, we conducted a varied series of regression experiments on commonly used benchmarks: 1D sinusoidal data, Pendulum, Hopper, Ant, and Humanoid, demonstrating PairEpEsts’ advantage over baselines in high-dimensional regression active learning.},
}

@article{berryshedding,
  title={Shedding Light on Large Generative Networks: Estimating Epistemic Uncertainty in Diffusion Models},
  author={Berry, Lucas and Brando, Axel and Meger, David},
  journal={The 40th Conference on Uncertainty in Artificial Intelligence},
  abbr={UAI},
  selected={true},
  year={2024},
  pdf={https://arxiv.org/pdf/2406.18580v1},
  code={https://github.com/nwaftp23/DECU},
  arxiv={2406.18580v1},
  abstract={Generative diffusion models, notable for their large parameter count (exceeding 100 million) and operation within high-dimensional image spaces, pose significant challenges for traditional uncertainty estimation methods due to computational demands. In this work, we introduce an innovative framework, Diffusion Ensembles for Capturing Uncertainty (DECU), designed for estimating epistemic uncertainty for diffusion models. The DECU framework introduces a novel method that efficiently trains ensembles of conditional diffusion models by incorporating a static set of pre-trained parameters, drastically reducing the computational burden and the number of parameters that require training. Additionally, DECU employs Pairwise-Distance Estimators (PaiDEs) to accurately measure epistemic uncertainty by evaluating the mutual information between model outputs and weights in high-dimensional spaces. The effectiveness of this framework is demonstrated through experiments on the ImageNet dataset, highlighting its capability to capture epistemic uncertainty, specifically in under-sampled image classes.},
}




@article{lotfi2023uncertainty,
  title={Uncertainty-aware hybrid paradigm of nonlinear MPC and model-based RL for offroad navigation: Exploration of transformers in the predictive model},
  author={Lotfi, Faraz and Virji, Khalil and Faraji, Farnoosh and Berry, Lucas and Holliday, Andrew and Meger, David and Dudek, Gregory},
  journal={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2024},
  abbr={ICRA},
  pdf={https://arxiv.org/pdf/2310.00760},
  selected={true},
  arxiv={2310.00760},
  code={https://github.com/FARAZLOTFI/offroad_autonomous_navigation/},
  abstract={In this paper, we investigate a hybrid scheme that combines nonlinear model predictive control (MPC) and model-based reinforcement learning (RL) for navigation planning of an autonomous model car across offroad, unstructured terrains without relying on predefined maps. Our innovative approach takes inspiration from BADGR, an LSTM-based network that primarily concentrates on environment modeling, but distinguishes itself by substituting LSTM modules with transformers to greatly elevate the performance our model. Addressing uncertainty within the system, we train an ensemble of predictive models and estimate the mutual information between model weights and outputs, facilitating dynamic horizon planning through the introduction of variable speeds. Further enhancing our methodology, we incorporate a nonlinear MPC controller that accounts for the intricacies of the vehicle's model and states. The model-based RL facet produces steering angles and quantifies inherent uncertainty. At the same time, the nonlinear MPC suggests optimal throttle settings, striking a balance between goal attainment speed and managing model uncertainty influenced by velocity. In the conducted studies, our approach excels over the existing baseline by consistently achieving higher metric values in predicting future events and seamlessly integrating the vehicle's kinematic model for enhanced decision-making. The code and the evaluation data are available at https://github.com/FARAZLOTFI/offroad_autonomous_navigation/).},
}


@inproceedings{berry2023normalizing,
  title={Normalizing flow ensembles for rich aleatoric and epistemic uncertainty modeling},
  author={Berry, Lucas and Meger, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={6},
  pages={6806--6814},
  year={2023},
  abbr={AAAI},
  pdf={https://arxiv.org/pdf/2302.01312},
  selected={true},
  oral={true},
  arxiv={2302.01312},
  code={https://github.com/nwaftp23/nflows_epistemic},
  abstract={In this work, we demonstrate how to reliably estimate epistemic uncertainty while maintaining the flexibility needed to capture complicated aleatoric distributions. To this end, we propose an ensemble of Normalizing Flows (NF), which are state-of-the-art in modeling aleatoric uncertainty. The ensembles are created via sets of fixed dropout masks, making them less expensive than creating separate NF models. We demonstrate how to leverage the unique structure of NFs, base distributions, to estimate aleatoric uncertainty without relying on samples, provide a comprehensive set of baselines, and derive unbiased estimates for differential entropy. The methods were applied to a variety of experiments, commonly used to benchmark aleatoric and epistemic uncertainty estimation: 1D sinusoidal data, 2D windy grid-world (Wet Chicken), Pendulum, and Hopper. In these experiments, we setup an active learning framework and evaluate each model’s capability at measuring aleatoric and epistemic uncertainty. The results show the advantages of using NF ensembles in capturing complicated aleatoric while maintaining accurate epistemic uncertainty estimates.},
}

